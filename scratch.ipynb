{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import hypernetx as hnx\n",
    "import itertools\n",
    "from sklearn.cluster import KMeans\n",
    "import tensorly as tl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate a random tensor\n",
    "n_nodes = 100\n",
    "m = 3\n",
    "K = 10\n",
    "dim = [K] * m\n",
    "\n",
    "# Randomly assign each node to a cluster\n",
    "clusters = np.random.randint(0,K,n_nodes)\n",
    "\n",
    "# One-hot encoding of the clusters\n",
    "one_hot = np.zeros((n_nodes,K))\n",
    "for i in range(n_nodes):\n",
    "    one_hot[i,clusters[i]] = 1\n",
    "one_hot = torch.tensor(one_hot)\n",
    "\n",
    "P_hat = torch.zeros(dim)\n",
    "for i in range(K):\n",
    "    for j in range(i,K):\n",
    "        for k in range(j,K):\n",
    "            # Random variable uniformly distributed between 0 and 1\n",
    "            p = np.random.uniform()\n",
    "            P_hat[i,j,k] = p\n",
    "            P_hat[i,k,j] = p\n",
    "            P_hat[j,i,k] = p\n",
    "            P_hat[j,k,i] = p\n",
    "            P_hat[k,i,j] = p\n",
    "            P_hat[k,j,i] = p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 10, 10])\n",
      "torch.Size([100, 10])\n"
     ]
    }
   ],
   "source": [
    "# Print the size of P_hat and one_hot\n",
    "print(P_hat.size())\n",
    "print(one_hot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl.set_backend('pytorch')\n",
    "P_hat = P_hat.float()\n",
    "one_hot = one_hot.float()\n",
    "Q = tl.tucker_to_tensor((P_hat, [one_hot,one_hot,one_hot]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 100, 100])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Q.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "# The adjacency tensor must be symmetric, then the factor matrices are same, so we can use the first one\n",
    "factor = factors[0]\n",
    "\n",
    "# Apply scale-invariant to the factor matrix\n",
    "factor = scale_invariant(factor)\n",
    "R_hat = factor[:, 1:]\n",
    "\n",
    "# Apply K-mean Clustering to the rows of factor matrix\n",
    "kmeans = KMeans(n_clusters=K, random_state=0).fit(R_hat)\n",
    "labels = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.1\n"
     ]
    }
   ],
   "source": [
    "# Calculate the accuracy of the clustering\n",
    "accuracy = np.sum(labels == clusters) / n_nodes\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tl.set_backend('pytorch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "def higher_order_orthogonal_iteration(tensor, ranks, n_iter_max=1000, tol=1e-10):\n",
    "    \"\"\"\n",
    "    Perform Higher Order Orthogonal Iteration (HOOI) on a 3D tensor.\n",
    "\n",
    "    Parameters:\n",
    "    - tensor: Input tensor of size I x J x K.\n",
    "    - ranks: Tuple of target ranks (r1, r2, r3).\n",
    "    - n_iter_max: Maximum number of iterations.\n",
    "    - eps: Convergence criterion.\n",
    "\n",
    "    Returns:\n",
    "    - L, R, V factor matrices.\n",
    "    - core_tensor: Core tensor of the Tucker decomposition.\n",
    "    \"\"\"\n",
    "    # Initialize factor matrices\n",
    "    I, J, K = tensor.shape\n",
    "    L = torch.randn(I, ranks[0])\n",
    "    R = torch.randn(J, ranks[1])\n",
    "    V = torch.randn(K, ranks[2])\n",
    "\n",
    "    # Initialize core tensor\n",
    "    core_tensor = torch.zeros(ranks)\n",
    "\n",
    "    # Iterate until convergence\n",
    "    for _ in range(n_iter_max):\n",
    "        # Update L\n",
    "        L = tl.tenalg.multi_mode_dot(tensor, [R, V], modes=[1, 2], transpose=True)\n",
    "        L = torch.linalg.qr(L)[0]\n",
    "\n",
    "        # Update R\n",
    "        R = tl.tenalg.multi_mode_dot(tensor, [L, V], modes=[0, 2], transpose=True)\n",
    "        R = torch.linalg.qr(R)[0]\n",
    "\n",
    "        # Update V\n",
    "        V = tl.tenalg.multi_mode_dot(tensor, [L, R], modes=[0, 1], transpose=True)\n",
    "        V = torch.linalg.qr(V)[0]\n",
    "\n",
    "        # Update core tensor\n",
    "        core_tensor = tl.tenalg.multi_mode_dot(tensor, [L, R, V], modes=[0, 1, 2])\n",
    "\n",
    "        # Compute the approximation error\n",
    "        error = torch.norm(tensor - core_tensor) / torch.norm(tensor)\n",
    "        if error < tol:\n",
    "            break\n",
    "\n",
    "    return L, R, V, core_tensor\n",
    "\n",
    "# Assuming we have a tensor 'A' and ranks r1, r2, r3 defined elsewhere.\n",
    "# The actual tensor A and its dimensions should be defined here.\n",
    "# For example:\n",
    "# A = torch.randn(10, 10, 10)\n",
    "# ranks = (3, 3, 3)\n",
    "# L, R, V, core_tensor = higher_order_orthogonal_iteration(A, ranks)\n",
    "\n",
    "# This code would then be executed with A and ranks defined, but for the purpose\n",
    "# of this example, we won't execute it as we don't have a real tensor A to work with.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "transpose() received an invalid combination of arguments - got (list), but expected one of:\n * (int dim0, int dim1)\n * (name dim0, name dim1)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m ranks \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m3\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Perform HOOI\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m L, R, V, core_tensor \u001b[38;5;241m=\u001b[39m \u001b[43mhigher_order_orthogonal_iteration\u001b[49m\u001b[43m(\u001b[49m\u001b[43mA\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mranks\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[23], line 29\u001b[0m, in \u001b[0;36mhigher_order_orthogonal_iteration\u001b[0;34m(tensor, ranks, n_iter_max, tol)\u001b[0m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Iterate until convergence\u001b[39;00m\n\u001b[1;32m     27\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_iter_max):\n\u001b[1;32m     28\u001b[0m     \u001b[38;5;66;03m# Update L\u001b[39;00m\n\u001b[0;32m---> 29\u001b[0m     L \u001b[38;5;241m=\u001b[39m \u001b[43mtl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtenalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmulti_mode_dot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mR\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mV\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtranspose\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m     L \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mlinalg\u001b[38;5;241m.\u001b[39mqr(L)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m     32\u001b[0m     \u001b[38;5;66;03m# Update R\u001b[39;00m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorly/backend/__init__.py:206\u001b[0m, in \u001b[0;36mBackendManager.dispatch_backend_method.<locals>.wrapped_backend_method\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_backend_method\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    203\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"A dynamically dispatched method\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \n\u001b[1;32m    205\u001b[0m \u001b[38;5;124;03m    Returns the queried method from the currently set backend\"\"\"\u001b[39;00m\n\u001b[0;32m--> 206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_THREAD_LOCAL_DATA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__dict__\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbackend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorly/tenalg/core_tenalg/n_mode_product.py:130\u001b[0m, in \u001b[0;36mmulti_mode_dot\u001b[0;34m(tensor, matrix_or_vec_list, modes, skip, transpose)\u001b[0m\n\u001b[1;32m    127\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m transpose:\n\u001b[0;32m--> 130\u001b[0m     res \u001b[38;5;241m=\u001b[39m \u001b[43mmode_dot\u001b[49m\u001b[43m(\u001b[49m\u001b[43mres\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mT\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconj\u001b[49m\u001b[43m(\u001b[49m\u001b[43mT\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmatrix_or_vec\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdecrement\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    132\u001b[0m     res \u001b[38;5;241m=\u001b[39m mode_dot(res, matrix_or_vec, mode \u001b[38;5;241m-\u001b[39m decrement)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorly/tenalg/core_tenalg/n_mode_product.py:73\u001b[0m, in \u001b[0;36mmode_dot\u001b[0;34m(tensor, matrix_or_vector, mode, transpose)\u001b[0m\n\u001b[1;32m     67\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m     68\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     69\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCan only take n_mode_product with a vector or a matrix.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     70\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProvided array of dimension \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mT\u001b[38;5;241m.\u001b[39mndim(matrix_or_vector)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not in [1, 2].\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     71\u001b[0m     )\n\u001b[0;32m---> 73\u001b[0m res \u001b[38;5;241m=\u001b[39m T\u001b[38;5;241m.\u001b[39mdot(matrix_or_vector, \u001b[43munfold\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m vec:  \u001b[38;5;66;03m# We contracted with a vector, leading to a vector\u001b[39;00m\n\u001b[1;32m     76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m vec_to_tensor(res, shape\u001b[38;5;241m=\u001b[39mnew_shape)\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorly/base.py:53\u001b[0m, in \u001b[0;36munfold\u001b[0;34m(tensor, mode)\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21munfold\u001b[39m(tensor, mode):\n\u001b[1;32m     40\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Returns the mode-`mode` unfolding of `tensor` with modes starting at `0`.\u001b[39;00m\n\u001b[1;32m     41\u001b[0m \n\u001b[1;32m     42\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[38;5;124;03m        unfolded_tensor of shape ``(tensor.shape[mode], -1)``\u001b[39;00m\n\u001b[1;32m     52\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 53\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m tl\u001b[38;5;241m.\u001b[39mreshape(\u001b[43mtl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmoveaxis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m, (tensor\u001b[38;5;241m.\u001b[39mshape[mode], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m))\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/tensorly/backend/__init__.py:206\u001b[0m, in \u001b[0;36mBackendManager.dispatch_backend_method.<locals>.wrapped_backend_method\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped_backend_method\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    203\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"A dynamically dispatched method\u001b[39;00m\n\u001b[1;32m    204\u001b[0m \n\u001b[1;32m    205\u001b[0m \u001b[38;5;124;03m    Returns the queried method from the currently set backend\"\"\"\u001b[39;00m\n\u001b[0;32m--> 206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mgetattr\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_THREAD_LOCAL_DATA\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__dict__\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mbackend\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_backend\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mname\u001b[49m\n\u001b[1;32m    208\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mmoveaxis\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.11/lib/python3.11/site-packages/numpy/core/numeric.py:1478\u001b[0m, in \u001b[0;36mmoveaxis\u001b[0;34m(a, source, destination)\u001b[0m\n\u001b[1;32m   1475\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dest, src \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mzip\u001b[39m(destination, source)):\n\u001b[1;32m   1476\u001b[0m     order\u001b[38;5;241m.\u001b[39minsert(dest, src)\n\u001b[0;32m-> 1478\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43mtranspose\u001b[49m\u001b[43m(\u001b[49m\u001b[43morder\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1479\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result\n",
      "\u001b[0;31mTypeError\u001b[0m: transpose() received an invalid combination of arguments - got (list), but expected one of:\n * (int dim0, int dim1)\n * (name dim0, name dim1)\n"
     ]
    }
   ],
   "source": [
    "# Example tensor of size 10 x 10 x 10\n",
    "A = torch.randn(10, 10, 10)\n",
    "# Desired ranks for the decomposition\n",
    "ranks = (3, 3, 3)\n",
    "# Perform HOOI\n",
    "L, R, V, core_tensor = higher_order_orthogonal_iteration(A, ranks)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "R = torch.randn(4, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-2.037881221987743e-17"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check if R has orthogonal columns\n",
    "R[:,0] @ R[:,1]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4, 2)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scipy.stats import ortho_group\n",
    "R = ortho_group.rvs(4)[:,:2]\n",
    "R.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "tensor = torch.rand(6, 6, 6)\n",
    "rank = (2, 2, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "I, J, K = tensor.shape\n",
    "R = ortho_group.rvs(J)[:,:rank[1]]\n",
    "R = torch.tensor(R, dtype=torch.float32)\n",
    "V = ortho_group.rvs(K)[:,:rank[2]]\n",
    "V = torch.tensor(V, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "R.T.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "def n_mode_product(x, u, n):\n",
    "    n = int(n)\n",
    "    # We need one letter per dimension\n",
    "    # (maybe you could find a workaround for this limitation)\n",
    "    if n > 26:\n",
    "        raise ValueError('n is too large.')\n",
    "    ind = ''.join(chr(ord('a') + i) for i in range(n))\n",
    "    exp = f'{ind}K...,JK->{ind}J...'\n",
    "    result = tf.einsum(exp, x, u)\n",
    "    return torch.tensor(result.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_mode_dot(tensor, matrices, modes):\n",
    "    res = tensor\n",
    "    for mode, matrix in zip(modes, matrices):\n",
    "        res = n_mode_product(res, matrix, mode)\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = n_mode_product(tensor, R.T, 1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 2, 2])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = n_mode_product(C, V.T, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = multi_mode_dot(tensor,[R.T, V.T], [1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unfold(tensor, mode):\n",
    "    \n",
    "    return torch.reshape(torch.moveaxis(tensor, mode, 0), (tensor.shape[mode], -1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "C_1 = unfold(tensor, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 36])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "C_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "U, _, _ = torch.svd(C_1)\n",
    "L = U[:, :rank[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 2])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "L.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HOOI(tensor, ranks, n_iter_max=100, tol=1e-8):\n",
    "    \"\"\"High-Order Orthogonal Iteration (HOOI) algorithm for Tucker decomposition\n",
    "    Perform Higher Order Orthogonal Iteration (HOOI) on a 3D tensor.\n",
    "\n",
    "    Parameters:\n",
    "    - tensor: Input tensor of size I x J x K.\n",
    "    - ranks: Tuple of target ranks (r1, r2, r3).\n",
    "    - n_iter_max: Maximum number of iterations.\n",
    "    - eps: Convergence criterion.\n",
    "\n",
    "    Returns:\n",
    "    - core_tensor: Core tensor of the Tucker decomposition.\n",
    "    - [L, R, V] factor matrices.\n",
    "    L ∈ R^I×r1, R ∈ R^J×r2, V ∈ R^K×r3.\n",
    "    \"\"\"\n",
    "    # Initialize R and V factor matrices with orthonormal columns\n",
    "    I, J, K = tensor.shape\n",
    "    R = ortho_group.rvs(J)[:,:ranks[1]]\n",
    "    R_hat = torch.tensor(R, dtype=torch.float32)\n",
    "    V = ortho_group.rvs(K)[:,:ranks[2]]\n",
    "    V_hat = torch.tensor(V, dtype=torch.float32)\n",
    "\n",
    "    for _ in range(n_iter_max):\n",
    "        # C = A ×2 R^T ×3 V^T\n",
    "        c = multi_mode_dot(tensor, [R_hat.T, V_hat.T], modes=[1, 2])\n",
    "        c_1 = unfold(c, 0)\n",
    "\n",
    "        # L = SVD(r1, C_1), where U = SVD(k, C) means compute the k’th order truncated \n",
    "        # SVD of C and then set U = [u1, u2, . . . , uk] to the matrix whose columns are \n",
    "        # the k largest left singular vectors ui of C\n",
    "        u, _, _ = torch.svd(c_1)\n",
    "        L_hat = u[:, :ranks[0]]\n",
    "\n",
    "        # D = A ×1 L^T ×3 V^T\n",
    "        d = multi_mode_dot(tensor, [L_hat.T, V_hat.T], modes=[0, 2])\n",
    "        d_2 = unfold(d, 1)\n",
    "\n",
    "        #R = SVD(r2, D_2)\n",
    "        u, _, _ = torch.svd(d_2)\n",
    "        R_hat = u[:, :ranks[1]]\n",
    "\n",
    "        # E = A ×1 L^T ×2 R^T\n",
    "        e = multi_mode_dot(tensor, [L_hat.T, R_hat.T], modes=[0, 1])\n",
    "        e_3 = unfold(e, 2)\n",
    "\n",
    "        # V = SVD(r3, E_3)\n",
    "        u, _, _ = torch.svd(e_3)\n",
    "        V_hat = u[:, :ranks[2]]\n",
    "\n",
    "        # Compute the approximation error\n",
    "        core_tensor = n_mode_product(e, V_hat.T, 2)\n",
    "        appr = multi_mode_dot(core_tensor, [L_hat, R_hat, V_hat], modes=[0, 1, 2])\n",
    "        if torch.norm(tensor - appr) < tol:\n",
    "            break\n",
    "\n",
    "    return core_tensor, [L_hat, R_hat, V_hat]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "core, factors = HOOI(tensor, rank)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "appr = multi_mode_dot(core, factors, modes=[0, 1, 2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.2515)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.norm(tensor - appr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[60], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Apply the Tucker decomposition to find the factor matrices\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m core, factors \u001b[38;5;241m=\u001b[39m \u001b[43mHOOI\u001b[49m\u001b[43m(\u001b[49m\u001b[43mQ\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mranks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43mK\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[59], line 31\u001b[0m, in \u001b[0;36mHOOI\u001b[0;34m(tensor, ranks, n_iter_max, tol)\u001b[0m\n\u001b[1;32m     26\u001b[0m C_1 \u001b[38;5;241m=\u001b[39m unfold(tensor, \u001b[38;5;241m0\u001b[39m)\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# L = SVD(r1, C_1), where U = SVD(k, C) means compute the k’th order truncated \u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# SVD of C and then set U = [u1, u2, . . . , uk] to the matrix whose columns are \u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;66;03m# the k largest left singular vectors ui of C\u001b[39;00m\n\u001b[0;32m---> 31\u001b[0m U, _, _ \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msvd\u001b[49m\u001b[43m(\u001b[49m\u001b[43mC_1\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     32\u001b[0m L \u001b[38;5;241m=\u001b[39m U[:, :ranks[\u001b[38;5;241m0\u001b[39m]]\n\u001b[1;32m     34\u001b[0m \u001b[38;5;66;03m# D = A ×1 L^T ×3 V^T\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Apply the Tucker decomposition to find the factor matrices\n",
    "core, factors = HOOI(Q, ranks=[K,K,K])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
